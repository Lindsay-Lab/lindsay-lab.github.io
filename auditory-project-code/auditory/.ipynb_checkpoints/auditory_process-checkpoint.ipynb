{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import hub\n",
    "from script import vggish_input, vggish_params\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_weight = '/scratch/bs4283/auditory_data/data_20sample/binary_weight3.pt'\n",
    "binary_bias = '/scratch/bs4283/auditory_data/data_20sample/binary_bias3.pt'\n",
    "tunning_value_folder = '/scratch/bs4283/auditory_data/data_20sample/tunnning_value/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort_tunning(x : str):\n",
    "    if '.' in x:\n",
    "        # 将文件名字用_进行分割\n",
    "        x = x.rpartition('.')\n",
    "        # 将x用.进行分割，最后拿到数字\n",
    "        x = x[0][-1]\n",
    "    else:\n",
    "        x = 0\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attnmats=[]\n",
    "fileList = os.listdir('/scratch/bs4283/auditory_data/data_20sample/tunnning_value')\n",
    "ss_path = '/scratch/bs4283/auditory_data/data_20sample/tunnning_value'\n",
    "fileList.sort(key=list_sort_tunning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = fileList[0]\n",
    "filepath = os.path.join(ss_path,filename)\n",
    "value = torch.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_qul = []\n",
    "for ss in range(13):\n",
    "    fv = b[ss]\n",
    "    max_v = np.amax(np.abs(fv),axis=0)\n",
    "    v_qul.append(max_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_qul = []\n",
    "for layer in range(6):\n",
    "    filename = fileList[layer]\n",
    "    filepath = os.path.join(ss_path,filename)\n",
    "    value = torch.load(filepath)\n",
    "    value = value.cpu().numpy()\n",
    "    max_v = np.amax(np.abs(value),axis=0)\n",
    "    v_qul.append(max_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x152e71011820>,\n",
       "  <matplotlib.lines.Line2D at 0x152e71011ac0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fb1af0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fb1d90>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fc1d90>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fd0070>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f5c070>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f5c310>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f69310>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f695b0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f7b5b0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f7b850>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x152e71011d60>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fb1040>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fc1070>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fc1310>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fd0310>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fd05b0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f5c5b0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f5c850>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f69850>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f69af0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f7baf0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f7bd90>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x152e71011580>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fb1850>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fc1af0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fd0d90>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f69070>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f7b310>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x152e70fb12e0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fc15b0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fd0850>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f5caf0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f69d90>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f88070>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x152e70fb1580>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fc1850>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70fd0af0>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f5cd90>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f7b070>,\n",
       "  <matplotlib.lines.Line2D at 0x152e70f88310>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKx0lEQVR4nO3dfVxUZd4/8M8wPCkCmTwIqTBBKxpkCimirJAuhckti5RlmncPW77aWhG1X+j2sgdXdgtNy4fSZUvXRS2Y3F1SE3fBxRhzJdwVtVtSDB8ghDsZNQUZrt8f3jPLcQaYwYEzc/i8X695xbnONXO+nmbmfOc614NKCCFARERE5ORc5A6AiIiIyB6Y1BAREZEiMKkhIiIiRWBSQ0RERIrApIaIiIgUgUkNERERKQKTGiIiIlIEJjVERESkCK5yB9Cb2tracOHCBXh7e0OlUskdDhEREVlBCIHLly8jODgYLi4dt8f0qaTmwoULGDp0qNxhEBERUTecPXsWQ4YM6XB/n0pqvL29Adw8KT4+PjJHQ0RERNbQ6/UYOnSo6TrekT6V1BhvOfn4+DCpISIicjJddR1hR2EiIiJSBCY1REREpAhMaoiIiEgRmNQQERGRIjCpISIiIkVgUkNERESKwKSGiIiIFIFJDRERESlCn5p8z9EZDAaUlpaitrYWQUFBiI+Ph1qtljssIiIip8CWGgeh1WoRHh6OxMREzJo1C4mJiQgPD4dWq5U7NCIiIqfApMYBaLVapKenIyoqCjqdDpcvX4ZOp0NUVBTS09OZ2BAREVlBJYQQcgfRW/R6PXx9fdHU1OQwaz8ZDAaEh4cjKioKO3fulCyp3tbWhtTUVFRWVqKqqoq3ooiIqE+y9vrNlhqZlZaW4syZM1iyZIkkoQEAFxcXZGVlobq6GqWlpTJFSERE5ByY1MistrYWABAZGWlxv7HcWI+IiIgsY1Ijs6CgIABAZWWlxf3GcmM9IiIisoxJjczi4+MRGhqKFStWoK2tTbKvra0N2dnZ0Gg0iI+PlylCIiIi58CkRmZqtRorV65EYWEhUlNTJaOfUlNTUVhYiJycHHYSJiIi6gIn33MAaWlpyM/Px8KFCxEXF2cq12g0yM/PR1pamozREREROYdutdSsX78eGo0Gnp6eiI6O7nRkTm1tLWbNmoXhw4fDxcUFGRkZZnUSEhKgUqnMHo888oipzuuvv262f/Dgwd0J3yGlpaXh22+/RXFxMfLy8lBcXIyqqiomNERERFayuaVmx44dyMjIwPr16zFhwgR8+OGHSE5OxvHjxzFs2DCz+s3NzfD398fSpUvx7rvvWnxNrVaLlpYW03ZjYyNGjRqFRx99VFLv3nvvxb59+0zbSrslo1arkZCQIHcYRERETsnmpGbVqlV49tln8dxzzwEAVq9ejS+++AIbNmxAdna2Wf3Q0FCsWbMGAPCHP/zB4mveeeedku3t27ejf//+ZkmNq6urolpniIiIyH5suv3U0tKC8vJyJCUlScqTkpJQVlZmt6Byc3Px+OOPw8vLS1JeVVWF4OBgaDQaPP744zh9+nSnr9Pc3Ay9Xi95EBERkTLZlNQ0NDTAYDAgMDBQUh4YGIi6ujq7BHTo0CFUVlaaWoKMxo0bhy1btuCLL77Apk2bUFdXh7i4ODQ2Nnb4WtnZ2fD19TU9hg4dapcYiYiIyPF0q6OwSqWSbAshzMq6Kzc3F5GRkRg7dqykPDk5GTNmzEBUVBSmTJmCzz//HACwefPmDl8rKysLTU1NpsfZs2ftEiMRERE5Hpv61Pj5+UGtVpu1ytTX15u13nTHjz/+iO3bt+PNN9/ssq6XlxeioqJQVVXVYR0PDw94eHjcdlxERETk+GxqqXF3d0d0dDSKiook5UVFRZL5Vbrrk08+QXNzM2bPnt1l3ebmZpw4cYLLBxARERGAbox+yszMxJw5cxATE4Px48dj48aNqKmpwbx58wDcvOVz/vx5bNmyxfScI0eOAACuXLmCixcv4siRI3B3d8fIkSMlr52bm4vU1FQMGjTI7LiLFi1CSkoKhg0bhvr6eixfvhx6vR5z58619Z9ARERECmRzUjNz5kw0NjbizTffRG1tLSIjI7Fr1y6EhIQAuDnZXk1NjeQ5o0ePNv1dXl6OvLw8hISE4MyZM6bykydP4sCBA9i7d6/F4547dw5PPPEEGhoa4O/vj9jYWBw8eNB0XCIiIurbVEIIIXcQvUWv18PX1xdNTU3w8fGROxwiIiKygrXXby5oSURERIrApIaIiIgUgUkNERERKQKTGiIiIlIEJjVERESkCExqiIiISBGY1BAREZEiMKkhIiIiRWBSQ0RERIrApIaIiIgUgUkNERERKQKTGiIiIlIEJjVERESkCExqiIiISBGY1BAREZEiMKkhIiIiRWBSQ0RERIrApIaIiIgUgUkNERERKQKTGiIiIlIEJjVERESkCExqiIiISBGY1BAREZEiMKkhIiIiRWBSQ0RERIrApIaIiIgUgUkNERERKQKTGiIiIlIEJjVERESkCExqiIiISBFc5Q6AqCcYDAaUlpaitrYWQUFBiI+Ph1qtljssIiLqQWypIcXRarUIDw9HYmIiZs2ahcTERISHh0Or1codGhER9SAmNaQoWq0W6enpiIqKgk6nw+XLl6HT6RAVFYX09HQmNkRECqYSQgi5g+gter0evr6+aGpqgo+Pj9zhkJ0ZDAaEh4cjKioKO3fuhIvLf3L2trY2pKamorKyElVVVbwVRUTkRKy9frOlhhSjtLQUZ86cwZIlSyQJDQC4uLggKysL1dXVKC0tlSlCIiLqSUxqSDFqa2sBAJGRkRb3G8uN9YiISFm6ldSsX78eGo0Gnp6eiI6O7vSXb21tLWbNmoXhw4fDxcUFGRkZZnU+/vhjqFQqs8f169e7fVzqe4KCggAAlZWVFvcby431iIhIWWxOanbs2IGMjAwsXboUFRUViI+PR3JyMmpqaizWb25uhr+/P5YuXYpRo0Z1+Lo+Pj6ora2VPDw9Pbt9XOp74uPjERoaihUrVqCtrU2yr62tDdnZ2dBoNIiPj5cpQiIi6lHCRmPHjhXz5s2TlEVERIhXX321y+dOmjRJzJ8/36z8o48+Er6+vj12XKOmpiYBQDQ1NVn9HHIuBQUFQqVSiZSUFFFWVib0er0oKysTKSkpQqVSiYKCArlDJCIiG1l7/bappaalpQXl5eVISkqSlCclJaGsrOy2kqsrV64gJCQEQ4YMwbRp01BRUXHbx21uboZer5c8SNnS0tKQn5+Po0ePIi4uDj4+PoiLi0NlZSXy8/ORlpYmd4hERNRDbJpRuKGhAQaDAYGBgZLywMBA1NXVdTuIiIgIfPzxx4iKioJer8eaNWswYcIE/Otf/8I999zT7eNmZ2fjjTfe6HZc5JzS0tIwffp0zihMRNTHdGuZBJVKJdkWQpiV2SI2NhaxsbGm7QkTJmDMmDF4//338d5773X7uFlZWcjMzDRt6/V6DB06tNtxkvNQq9VISEiQOwwiIupFNiU1fn5+UKvVZq0j9fX1Zq0ot8PFxQUPPPAAqqqqbuu4Hh4e8PDwsFtcRERE5Lhs6lPj7u6O6OhoFBUVScqLiooQFxdnt6CEEDhy5Ihp6G1vHZeIiIicl823nzIzMzFnzhzExMRg/Pjx2LhxI2pqajBv3jwAN2/5nD9/Hlu2bDE958iRIwBudga+ePEijhw5And3d4wcORIA8MYbbyA2Nhb33HMP9Ho93nvvPRw5cgTr1q2z+rhERETUt9mc1MycORONjY148803UVtbi8jISOzatQshISEAbk62d+vcMaNHjzb9XV5ejry8PISEhODMmTMAgEuXLuH5559HXV0dfH19MXr0aPzjH//A2LFjrT4uERER9W1c0JKIiIgcGhe0JCIioj6FSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSK4yh0A/YfBYEBpaSlqa2sRFBSE+Ph4qNVqucMiIiJyCmypcRBarRbh4eFITEzErFmzkJiYiPDwcGi1WrlDIyIicgpMahyAVqtFeno6oqKioNPpcPnyZeh0OkRFRSE9PZ2JDRERkRVUQgghdxC9Ra/Xw9fXF01NTfDx8ZE7HAA3bzmFh4cjKioKO3fuhIvLf/LMtrY2pKamorKyElVVVbwVRUREfZK112+21MistLQUZ86cwZIlSyQJDQC4uLggKysL1dXVKC0tlSlCIiIi58CkRma1tbUAgMjISIv7jeXGekRERGQZkxqZBQUFAQAqKyst7jeWG+sRERGRZUxqZBYfH4/Q0FCsWLECbW1tkn1tbW3Izs6GRqNBfHy8TBESERE5ByY1MlOr1Vi5ciUKCwuRmpoqGf2UmpqKwsJC5OTksJMwERFRFzj5ngNIS0tDfn4+Fi5ciLi4OFO5RqNBfn4+0tLSZIyOiIjIOXBItwPhjMJERETmrL1+s6XGgajVaiQkJMgdBhERkVNinxoiIiJSBCY1REREpAhMaoiIiEgRmNQQERGRIjCpISIiIkVgUkNERESKwKSGiIiIFIFJDRERESkCkxoiIiJShG4lNevXr4dGo4Gnpyeio6NRWlraYd3a2lrMmjULw4cPh4uLCzIyMszqbNq0CfHx8Rg4cCAGDhyIKVOm4NChQ5I6r7/+OlQqleQxePDg7oRPRERECmRzUrNjxw5kZGRg6dKlqKioQHx8PJKTk1FTU2OxfnNzM/z9/bF06VKMGjXKYp2SkhI88cQTKC4uhk6nw7Bhw5CUlITz589L6t17772ora01PY4ePWpr+ERERKRQNi9oOW7cOIwZMwYbNmwwlY0YMQKpqanIzs7u9LkJCQm4//77sXr16k7rGQwGDBw4EGvXrsVTTz0F4GZLzc6dO3HkyBFbwpVw9AUtiYiIyJy112+bWmpaWlpQXl6OpKQkSXlSUhLKysq6F6kFP/74I27cuIE777xTUl5VVYXg4GBoNBo8/vjjOH36tN2OSURERM7NplW6GxoaYDAYEBgYKCkPDAxEXV2d3YJ69dVXcdddd2HKlCmmsnHjxmHLli34yU9+gu+//x7Lly9HXFwcjh07hkGDBll8nebmZjQ3N5u29Xq93WIkIiIix9KtjsIqlUqyLYQwK+uut99+G9u2bYNWq4Wnp6epPDk5GTNmzEBUVBSmTJmCzz//HACwefPmDl8rOzsbvr6+psfQoUPtEiMRERE5HpuSGj8/P6jVarNWmfr6erPWm+7IycnBihUrsHfvXtx3332d1vXy8kJUVBSqqqo6rJOVlYWmpibT4+zZs7cdIxERETkmm5Iad3d3REdHo6ioSFJeVFSEuLi42wrknXfewVtvvYU9e/YgJiamy/rNzc04ceIEgoKCOqzj4eEBHx8fyYOIiIiUyaY+NQCQmZmJOXPmICYmBuPHj8fGjRtRU1ODefPmAbjZOnL+/Hls2bLF9BzjiKUrV67g4sWLOHLkCNzd3TFy5EgAN285vfbaa8jLy0NoaKipJWjAgAEYMGAAAGDRokVISUnBsGHDUF9fj+XLl0Ov12Pu3Lm3dQKIiIhIGWxOambOnInGxka8+eabqK2tRWRkJHbt2oWQkBAANyfbu3XOmtGjR5v+Li8vR15eHkJCQnDmzBkANyfza2lpQXp6uuR5y5Ytw+uvvw4AOHfuHJ544gk0NDTA398fsbGxOHjwoOm4RERE1LfZPE+NM+M8NURERM6nR+apISIiInJUTGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREiuAqdwBERH2BwWBAaWkpamtrERQUhPj4eKjVarnDIlIUttQQEfUwrVaL8PBwJCYmYtasWUhMTER4eDi0Wq3coREpCpMaIqIepNVqkZ6ejqioKOh0Oly+fBk6nQ5RUVFIT09nYkNkRyohhJA7iN6i1+vh6+uLpqYm+Pj4yB0OESmcwWBAeHg4oqKisHPnTri4/Od3ZFtbG1JTU1FZWYmqqireiiLqhLXXb7bUEBH1kNLSUpw5cwZLliyRJDQA4OLigqysLFRXV6O0tFSmCImUhUkNEVEPqa2tBQBERkZa3G8sN9YjotvDpIaIqIcEBQUBACorKy3uN5Yb6xHR7elWUrN+/XpoNBp4enoiOjq606bT2tpazJo1C8OHD4eLiwsyMjIs1isoKMDIkSPh4eGBkSNH4rPPPrut4xIRyS0+Ph6hoaFYsWIF2traJPva2tqQnZ0NjUaD+Ph4mSIkUhabk5odO3YgIyMDS5cuRUVFBeLj45GcnIyamhqL9Zubm+Hv74+lS5di1KhRFuvodDrMnDkTc+bMwb/+9S/MmTMHjz32GL766qtuH5eISG5qtRorV65EYWEhUlNTJaOfUlNTUVhYiJycHHYSJrITm0c/jRs3DmPGjMGGDRtMZSNGjEBqaiqys7M7fW5CQgLuv/9+rF69WlI+c+ZM6PV67N6921T28MMPY+DAgdi2bdttH9eIo5+ISA5arRYLFy7EmTNnTGUajQY5OTlIS0uTLzAiJ9Ejo59aWlpQXl6OpKQkSXlSUhLKysq6FyluttTc+poPPfSQ6TW7e9zm5mbo9XrJg4iot6WlpeHbb79FcXEx8vLyUFxcjKqqKiY0RHZm0zIJDQ0NMBgMCAwMlJQHBgairq6u20HU1dV1+prdPW52djbeeOONbsdFRGQvarUaCQkJcodBpGjd6iisUqkk20IIs7KeeE1bj5uVlYWmpibT4+zZs7cVIxERETkum1pq/Pz8oFarzVpH6uvrzVpRbDF48OBOX7O7x/Xw8ICHh0e34yIiIiLnYVNLjbu7O6Kjo1FUVCQpLyoqQlxcXLeDGD9+vNlr7t271/SaPXVcIiIiUg6bWmoAIDMzE3PmzEFMTAzGjx+PjRs3oqamBvPmzQNw85bP+fPnsWXLFtNzjhw5AgC4cuUKLl68iCNHjsDd3R0jR44EAMyfPx8//elP8bvf/Q7Tp0/Hn//8Z+zbtw8HDhyw+rhERETUt9mc1MycORONjY148803UVtbi8jISOzatQshISEAbk62d+vcMaNHjzb9XV5ejry8PISEhJiGN8bFxWH79u349a9/jddeew1hYWHYsWMHxo0bZ/VxiYiIqG/jKt1ERETk0LhKNxEREfUpTGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJFYFJDREREisCkhoiIiBSBSQ0REREpApMaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqSEiIiJF6FZSs379emg0Gnh6eiI6OhqlpaWd1t+/fz+io6Ph6emJu+++Gx988IFkf0JCAlQqldnjkUceMdV5/fXXzfYPHjy4O+ETERGRAtmc1OzYsQMZGRlYunQpKioqEB8fj+TkZNTU1FisX11djalTpyI+Ph4VFRVYsmQJfvWrX6GgoMBUR6vVora21vSorKyEWq3Go48+Knmte++9V1Lv6NGjtoZPRERECuVq6xNWrVqFZ599Fs899xwAYPXq1fjiiy+wYcMGZGdnm9X/4IMPMGzYMKxevRoAMGLECBw+fBg5OTmYMWMGAODOO++UPGf79u3o37+/WVLj6urK1hkiIiKyyKaWmpaWFpSXlyMpKUlSnpSUhLKyMovP0el0ZvUfeughHD58GDdu3LD4nNzcXDz++OPw8vKSlFdVVSE4OBgajQaPP/44Tp8+3Wm8zc3N0Ov1kgcREREpk01JTUNDAwwGAwIDAyXlgYGBqKurs/icuro6i/VbW1vR0NBgVv/QoUOorKw0tQQZjRs3Dlu2bMEXX3yBTZs2oa6uDnFxcWhsbOww3uzsbPj6+poeQ4cOtfafSkRERE6mWx2FVSqVZFsIYVbWVX1L5cDNVprIyEiMHTtWUp6cnIwZM2YgKioKU6ZMweeffw4A2Lx5c4fHzcrKQlNTk+lx9uzZzv9hRERE5LRs6lPj5+cHtVpt1ipTX19v1hpjNHjwYIv1XV1dMWjQIEn5jz/+iO3bt+PNN9/sMhYvLy9ERUWhqqqqwzoeHh7w8PDo8rWIiIjI+dnUUuPu7o7o6GgUFRVJyouKihAXF2fxOePHjzerv3fvXsTExMDNzU1S/sknn6C5uRmzZ8/uMpbm5macOHECQUFBtvwTiIiISKFsvv2UmZmJ3//+9/jDH/6AEydOYMGCBaipqcG8efMA3Lzl89RTT5nqz5s3D9999x0yMzNx4sQJ/OEPf0Bubi4WLVpk9tq5ublITU01a8EBgEWLFmH//v2orq7GV199hfT0dOj1esydO9fWfwIREREpkM1DumfOnInGxka8+eabqK2tRWRkJHbt2oWQkBAAQG1trWTOGo1Gg127dmHBggVYt24dgoOD8d5775mGcxudPHkSBw4cwN69ey0e99y5c3jiiSfQ0NAAf39/xMbG4uDBg6bjErVnMBhQWlqK2tpaBAUFIT4+Hmq1Wu6wiIioB6mEsdduH6DX6+Hr64umpib4+PjIHQ71EK1Wi4ULF+LMmTOmstDQUKxcuRJpaWnyBUZERN1i7fWbaz+Romi1WqSnpyMqKgo6nQ6XL1+GTqdDVFQU0tPTodVq5Q6RiIh6CFtqSDEMBgPCw8MRFRWFnTt3wsXlPzl7W1sbUlNTUVlZiaqqKt6KIiJyImypoT6ntLQUZ86cwZIlSyQJDQC4uLggKysL1dXVXS7ASkREzolJDSlGbW0tACAyMtLifmO5sR4RESkLkxpSDOOcRZWVlRb3G8s5txERkTIxqSHFiI+PR2hoKFasWIG2tjbJvra2NmRnZ0Oj0SA+Pl6mCImIqCcxqSHFUKvVWLlyJQoLC5GamioZ/ZSamorCwkLk5OSwkzARkULZPPkekSNLS0tDfn4+Fi5cKFm6Q6PRID8/n/PUEBEpGId0kyJxRmEiIuWw9vrNlhpSJLVajYSEBLnDIKIewB8t1BH2qSEiIqeh1WoRHh6OxMREzJo1C4mJiQgPD+ds4QSASQ0RETkJLoNCXWGfGiIicnhcBqVv4zIJTshgMKCkpATbtm1DSUkJDAaD3CERETkELoNC1mBS4yB4n5iIqGNcBoWswaTGAfA+MRFR57gMClmDfWpkxvvERERd43dl38Y+NU6C94mJiLrGZVDIGpx8T2a8T0xEZB0ug0JdYVIjs/b3iWNjY8328z4xyYkzt5KjSUtLw/Tp0/m+JIvYp0ZmvE9Mjkqr1WLhwoU4c+aMqSw0NBQrV67kL2Ii6lXsU+MkeJ+YHBFH5BGRM2JLjYOw9KtYo9EgJyeHv4qpV7H1kIgcjbXXbyY1DoT9F8gRlJSUIDExETqdzmI/L51Oh7i4OBQXF3MldCLqFdZev9lR2IGo1WpeJEh2HJFHRM6KfWqISIIztxKRs2JSQ0QS8fHxCA0NxYoVK9DW1ibZ19bWhuzsbGg0GsTHx8sUIRGRZUxqiEiCI/KIyFmxTw0RmeHMrUTkjDj6iYg6xBF5ROQIOPqJiG4bR+SRI2KyTR1hUkOKxC89ImXi8h3UGXYUJsXRarUIDw9HYmIiZs2ahcTERISHh3NqfyInx+U7qCtMakhR+KVHpEwGgwELFy7EtGnTsHPnTsTGxmLAgAGIjY3Fzp07MW3aNCxatAgGg0HuUElG7ChMisE1i4iUi8t39G1cpZv6nNLSUpw5cwZLliyRJDQA4OLigqysLFRXV6O0tFSmCImou7h8B1mjW0nN+vXrodFo4Onpiejo6C4vEvv370d0dDQ8PT1x991344MPPpDs//jjj6FSqcwe169fv63jUt/CLz0i5eLyHWQNm5OaHTt2ICMjA0uXLkVFRQXi4+ORnJyMmpoai/Wrq6sxdepUxMfHo6KiAkuWLMGvfvUrFBQUSOr5+PigtrZW8vD09Oz2canv4ZcekXJx+Q6yirDR2LFjxbx58yRlERER4tVXX7VY/5VXXhERERGSshdeeEHExsaatj/66CPh6+tr1+Na0tTUJACIpqYmq59DzqO1tVWEhoaKlJQUYTAYJPsMBoNISUkRGo1GtLa2yhQhEd2OgoICoVKpREpKiigrKxN6vV6UlZWJlJQUoVKpREFBgdwhUg+x9vptU0tNS0sLysvLkZSUJClPSkpCWVmZxefodDqz+g899BAOHz6MGzdumMquXLmCkJAQDBkyBNOmTUNFRcVtHRcAmpubodfrJQ9SLq5ZRKRsxuU7jh49iri4OPj4+CAuLg6VlZVcvoMA2Dj5XkNDAwwGAwIDAyXlgYGBqKurs/icuro6i/VbW1vR0NCAoKAgRERE4OOPP0ZUVBT0ej3WrFmDCRMm4F//+hfuueeebh0XALKzs/HGG2/Y8k8kJ8c1i4iULS0tDdOnT+fkmmRRt2YUVqlUkm0hhFlZV/Xbl8fGxkqG6E2YMAFjxozB+++/j/fee6/bx83KykJmZqZpW6/XY+jQoR3WJ2Xglx45Is5ybT9cvoM6YlNS4+fnB7VabdY6Ul9fb9aKYjR48GCL9V1dXTFo0CCLz3FxccEDDzyAqqqqbh8XADw8PODh4dHlv4uUh1965Eg4tT9R77CpT427uzuio6NRVFQkKS8qKpI09bc3fvx4s/p79+5FTEwM3NzcLD5HCIEjR46YRql057hERI6As1zbn8FgQElJCbZt24aSkhLOIkz/YWsP5O3btws3NzeRm5srjh8/LjIyMoSXl5c4c+aMEEKIV199VcyZM8dU//Tp06J///5iwYIF4vjx4yI3N1e4ubmJ/Px8U53XX39d7NmzR5w6dUpUVFSIp59+Wri6uoqvvvrK6uNag6OfiGzT2toqiouLRV5eniguLubIMRtxRJ79FRQUiNDQUAHA9AgNDeXIJ4Wz9vptc1IjhBDr1q0TISEhwt3dXYwZM0bs37/ftG/u3Lli0qRJkvolJSVi9OjRwt3dXYSGhooNGzZI9mdkZIhhw4YJd3d34e/vL5KSkkRZWZlNx7UGkxoi6/HicfuKi4sFAKHT6SzuLysrEwBEcXFx7wbmpNoP6dbpdOLy5ctCp9NxSHcf0KNJjbNiUkNkHV487CMvL08AEJcvX7a4X6/XCwAiLy+vlyNzPmz16tt6ZJ4aIlK+9qshf/LJJzh48CCysrJw8OBBfPLJJ1wN2Qac5dp+uLYbWaNbQ7qJHB2Hz3af8eIxYcIEeHt7o7W11bRv8eLFeOyxx0wXD44w61z7qf0trRzPqf2tx7XdyBpsqSHF0Wq1CA8PR2JiImbNmoXExESEh4dzlImVjBeFP/3pTxg0aBA2bdqE2tpabNq0CYMGDUJeXp6kHnWMs1zbT/tWL0ujn9jqRQBbakhhjMNnH3nkESxevBj9+vXDtWvXsHv3bqSnp3NWYSsY54+688478d1330Gn06G4uBjh4eH47rvvEBwcjP/93//tcJ4pkuIs1/ZhbPV6+eWXcfHiRXz33XemfSEhIfD392erFzGpIeUw9gWJjo5GZWUlCgsLTftCQ0MRHR2NRYsWYfr06fxl3ImjR48CALy9vTF8+HCzi4e3tzf+93//F0ePHjVbj40s4yzXt0+tVuPRRx/FO++8g8DAQGzcuBHTpk1DYWEhXnvtNRw+fBiLFy/mOe3jVEL835oFfYBer4evry+amprg4+MjdzhkZyUlJUhMTIRKpcIjjzyC5ORkSUvN559/DiEEiouL2RekEy+//DLWrl0L4GYHzLa2NtO+9tsvvfQS3n//fVlipL7HYDAgPDwcfn5+aGhokMzOrNFoMGjQIDQ2NqKqqoqJjQJZe/1mSw0pxvnz5wEA999/v8WWmvvvvx8VFRWmemRZaGio6W8PDw9cu3bN4nb7ekQ9zdiBfdu2bXjggQfMWr0OHTqEuLg4dmDv45jUkGJcvHgRAHDkyBFMmzYN27ZtQ2RkJCorK7FixQpTkmOsR5aNHDkSAODm5obGxkZ89dVXpovHuHHj4Ovrixs3bpjqEfWG9qOfLK3txtFPBHD0EymIseOqv78/tFotYmNjMWDAAMTGxkKr1cLf319SjywrKysDANy4cQMajQYnT57EpEmTcPLkSWg0Gty4cUNSj6g3cM4fsgZbakgxGhsbAdxcvf3nP/85Hn74YVOfmj179qC+vl5Sjzr32GOPoaCgAC+88IKpzNhZ89NPP5UxMuqLOOcPWYNJDSmGsSVGo9Fg9+7dkj41rq6u0Gg0qK6uNtUjyxISErB8+XL8+9//xpAhQySjn4YMGWIaHcV+C9SbjHP+pKenIzU1FVlZWabby9nZ2SgsLER+fj47CfdxTGpIMe666y4AQHV1NQIDAzF79mzcfffdOH36NLZu3Yrq6mpJPbIsISEBvr6++OabbxAQEICFCxeazuMf//hHfPfdd/D19WVSQ72Oc/5QVzikmxSjpaUFXl5e8PLygq+vL2pqakz7QkJCcOnSJVy9ehVXr16Fu7u7jJE6NoPBgKCgoE47VAcEBODChQv8VUyyaGlpwfr163Hq1CmEhYXhxRdf5Gda4ay9frOjMClGWVkZWltbodfrcd9992Ht2rXIzc3F2rVrERUVBb1ej9bWVnZw7UJpaakpoenXr59kn3G7vr6eCweSLLRaLYYPH44FCxZg7dq1WLBgAYYPH85lUAgAkxpSEONQzj/+8Y+orKzESy+9hGeffRYvvfQSjh07hj/+8Y+SemSZcR6f0aNHIyAgQLIvICAAo0ePltQj6i3GZVCioqIk62hFRUUhPT2diQ0xqXEklhZpI+sZh3KGhYXh22+/RXFxMfLy8lBcXIyqqircfffdknpkmbGVpqKiAvfdd5/k4nHfffehoqJCUo+oNxiXQZk2bRp27twpmbJh586dmDZtGhYtWsTvzT6OSY2D4MrSt6/9kM/2U/sDHPJpC+M8PgEBARbn+zG23nC+H+pNxhmFlyxZAiGE5AegEAJZWVmorq7mbdE+jqOfHICxSdXSLLhcWdp67Yd8+vr6Sqb379evH65fv84hn1YwzuNz8eJFi/P9GFtoON8P9SbjbeNTp07hiSeekKz9FBoaiuXLl0vqUd/EpEZmtzapGieUMjappqamcmVpG1ka0KdSqSyWkznjPD6hoaHYs2eP2Xw/oaGhnO+Hep3xtvGcOXMs/gCcM2eOpB71TRzSLTPjytI6nQ6xsbFm+3U6HeLi4riytBWMq/hGRUWhoKAAX375pWnNogkTJmDGjBmorKzkKr5dML4nAfNksP0235PUm4xTNgwaNAjnzp2Dq+t/fpO3trZiyJAhaGxs5JQNCsVVup1E+0XaLOEibdZrv4qvm5ub2QU3KyuLq/haIS4uDi4uLmhra4OHhweuX79u2mfcdnFxkUx+RtTTjFM2fP/99xZvi37//femevx8911MamTWfpE2Sy01XKTNekwQ7aO0tNTU0Xry5MlITk42XTx2796Nzz//HG1tbSgtLcXkyZNljpb6CuPndv78+Vi3bp3ZbdH58+djzZo1/Hz3cUxqZMZF2uynfYL4wAMPoLS01HT7KT4+ngmilUpKSgAAr7/+Oj7++GN8/vnnpn0ajQbLli3DG2+8gZKSEiY11GuMn9s1a9Zg2rRpZsn2mjVrJPWob2JSI7P2I3amT59u1qT6+eefc8SOlYwJ4ssvv4yGhgaz0RF+fn5MEG0QHx+PX//612bJYXFxsdyhUR8UFxcHV1dXDBo0CJ999pmkT83zzz9v6lPD26J9nOhDmpqaBADR1NQkdyhmFi9eLFxdXQUA08PV1VUsXrxY7tCcyuLFiwUAERgYKDZu3CguXLggNm7cKAIDAwUAnk8r7Nu3TwAQEydOFAaDQbLPYDCIiRMnCgBi3759MkVIfVFxcbEAIFQqlUhJSRFlZWVCr9eLsrIykZKSIlQqlQAgiouL5Q6VeoC112+OfnIAxnlqHnnkEYv9FzhPjXWMo5/8/Pxw8eJFfPfdd6Z9xpaaxsZGjn7qQvsFLTt6T3JBS+pt27Ztw6xZs7B161b8+te/lrTEajQavPXWW5g9ezby8vLwxBNPyBco9Qhrr99MamTWfhiypT41qampHIZspfbD4y31qTl06BCHx1tJq9VixowZHQ7pLigoYKJNvYqf776Nq3Q7ifZTf7dPaADAxcWFU3/bgKOf7M/Dw0Oy7enpKVMk1Ne1H1ShUqmQkJCAJ554AgkJCVCpVBxUQQCY1MiOF2L7MY56WLt2rcV1tNauXSupR5YZZ7lOSUmBXq+XLAza1NSElJQULhxIvc44qKKwsBCpqamShVZTU1NRWFiInJwctmj3dT3eu8eBOGJHYWPnN51OZ3F/WVkZO79ZqbW1VQQEBAgAYtq0aUKn04nLly8LnU4npk2bJgCIgIAA0draKneoDo3vSXJkBQUFIjQ0VDKoQqPRiIKCArlDox5k7fWbQ7plxnlq7Eu06/8hhDA9yHpsPSRHlpaWhunTp5v1qWELDQG8/SQ7NqnaT2lpKS5evIjs7GxUVlYiLi4OPj4+iIuLw7Fjx7BixQrU19ezf1IX2k9iaAknMSQih9ULrUYOwxFvPxkVFBSIkJAQSZNqaGgom1RtkJeXJwCIy5cvi9bWVlFcXCzy8vJEcXGxaG1tFXq9XgAQeXl5cofq0FpbW0VoaKhISUmxOE9NSkqK0Gg0vI1HsrB0+4nflcrH209OSKVSyR2CU7t1Ha1bh3WyhcE67We5Tk1NRVZWFiIjI1FZWYns7GwUFhZylmuSRfs5vRYvXiyZPyk9PZ1zehHnqXEEnHzPPjjnj31ptVosXLjQbJKznJwcvh+p17WfXLO+vh41NTWmfcOGDUNAQAAn17SRwWBwmr5JnHzPAkdMajqbBTckJAT+/v78oNqgfYLY0TpavCBbz5m+9EjZjJPvATB9ro3ab3PyPetY+tESGhqKlStXOuR3pNXX7+7c21q3bp0IDQ0VHh4eYsyYMeIf//hHp/VLSkrEmDFjhIeHh9BoNGLDhg2S/Rs3bhQTJ04Ud9xxh7jjjjvE5MmTxVdffSWps2zZMsk9VPzf+j62cMQ+NcbhswBESkqKZBhySkqKaR+Hz1qP62gRKc/WrVtNn+epU6eK+fPni+eff17Mnz9fTJ061bRv69atcofq8AoKCkxraN16zVGpVA7ZP8na67fNSc327duFm5ub2LRpkzh+/LiYP3++8PLyEt99953F+qdPnxb9+/cX8+fPF8ePHxebNm0Sbm5uIj8/31Rn1qxZYt26daKiokKcOHFCPP3008LX11ecO3fOVGfZsmXi3nvvFbW1taZHfX29TbE7YlJj/KAmJydb7JSZnJzMD6oNjB/WqVOnihkzZogHH3xQzJgxQ0ydOtVhP6xE1LWcnBwBQPj7+1v80eLn5ycAiJycHLlDdWjOOhCgx5KasWPHinnz5knKIiIixKuvvmqx/iuvvCIiIiIkZS+88IKIjY3t8Bitra3C29tbbN682VS2bNkyMWrUKFvDlXDEpObdd98VAMSmTZss7v/www8FAPHuu+/2bmBOyPhhDQsLE2q1WvKlp1arRVhYmEN+WImoa0uWLDF9nv39/cWiRYvE+vXrxaJFi4S/v79p35IlS+QO1aG1n1yzublZvPvuu+Kll14S7777rmhubnbYyTWtvX7bNE9NS0sLysvLkZSUJClPSkpCWVmZxefodDqz+g899BAOHz6MGzduWHzOjz/+iBs3buDOO++UlFdVVSE4OBgajQaPP/44Tp8+3Wm8zc3N0Ov1koej8ff3B3Dz/mZbW5tkX1tbG3bu3CmpRx0zrqN16tQp+Pn5YdOmTaitrcWmTZvg5+eHU6dOcR0tIifV/vvxypUryMnJwYsvvoicnBxcuXLFYj0yZ5w0c/v27fDy8sKCBQuwdu1aLFiwAF5eXtixY4eknrOxKalpaGiAwWBAYGCgpDwwMBB1dXUWn1NXV2exfmtrKxoaGiw+59VXX8Vdd92FKVOmmMrGjRuHLVu24IsvvsCmTZtQV1eHuLg4NDY2dhhvdnY2fH19TY+hQ4da+0/tNXfddRcAYM+ePRYn39uzZ4+kHnXs7NmzAG4mgOfOncNzzz2HwYMH47nnnsO5c+dMiaGxHhE5j0uXLnW4r/10GJ3Vo/9MabFmzRoMGjRI8uNv0KBBWLNmjaSes+nWPDW3zqcihOh0jhVL9S2VA8Dbb7+Nbdu2oaSkRLIicHJysunvqKgojB8/HmFhYdi8eTMyMzMtHjcrK0uyT6/XO1xiY1wmwc/PD0ePHkVcXJxpn0ajQXR0NBobG7lMghW++uorAMCzzz4LV1fpW9vV1RVPP/003n77bXz11VeYM2eOHCESkR0kJiZi6tSpplFPu3btwq5du+QOyymMGzcOAODu7o6amhq4u7sDAJ577jk89dRT8Pb2RktLi6mes7EpqfHz84NarTZrlamvrzdrjTEaPHiwxfqurq4YNGiQpDwnJwcrVqzAvn37cN9993Uai5eXF6KiolBVVdVhHQ8PD3h4eHT6OnJrP9HZI488gkWLFlkchsxhtF0zJstff/012trazOapqaiokNSjrnFINzmK9u+74uJiSRLTv39/i/XI3IcffgjgZneS9PR0s8k1W1paTPUyMjJkjLR7bLr95O7ujujoaBQVFUnKi4qKJC0M7Y0fP96s/t69exETEwM3NzdT2TvvvIO33noLe/bsQUxMTJexNDc348SJE07bRNZeWloa8vPzUVlZiZdeegnPPvssXnrpJRw7dozzqtjgnnvuAXDz/WjpVt6+ffsk9ahzWq0WYWFhSExMxKxZs5CYmIiwsDBotVq5Q3NKBoMBJSUlppZog8Egd0hOxdhycOscNcDNfpj9+vWT1CPLTp06BQD4/e9/b7o7YFwjr7KyEps2bZLUczY2337KzMzEnDlzEBMTg/Hjx2Pjxo2oqanBvHnzANy85XP+/Hls2bIFADBv3jysXbsWmZmZ+MUvfgGdTofc3Fxs27bN9Jpvv/02XnvtNeTl5SE0NNTUsjNgwAAMGDAAALBo0SKkpKRg2LBhqK+vx/Lly6HX6zF37tzbPgm94ccff8Q333zT4f7Q0FB88sknOHjwIL755htEREQgNjYWarUaX3/9dYfPi4iIkPxK6ctefPFFLF68GF5eXvj3v/8tSbRDQ0Ph4+ODq1ev4sUXX5QxSueg1WoxY8YMs5bOuro6zJgxAwUFBUy2baDVapGZmWk2ueaqVat4Hq1k7Dpwa0JjZCx3tC4GjiYsLAzAzRbrb7/91qwlNjc3V1LP6XRnaNW6detESEiIcHd3F2PGjBH79+837Zs7d66YNGmSpH5JSYkYPXq0cHd3F6GhoWaT7926kKPxsWzZMlOdmTNniqCgIOHm5iaCg4NFWlqaOHbsmE1xyzmku7y83OK/8XYf5eXlvf5vcWSLFy8WAISLi4vkPBm3OQFf11pbWyVDZC09AgICODTeSgUFBQKA6Nevn+QcGrc5d5J1mpubrfpObG5uljtUh9bc3CxcXV1FYGCguH79umTh3+vXr4vAwEDh6urqcOfR2us3l0noJV211BidOHECs2fPxtatWzFixIgu67OlRsrYwqBSqSR9Z4zbbGHo2t/+9jfTyEN3d3ekp6cjJiYGhw8fRn5+vume+759+zB58mQ5Q3V4BoMBQUFBuHjxIqZNm4alS5ea+i/85je/QWFhIQICAnDhwgX2BenC7t27MXXq1C7r7dq1SzKwhMy98soreOedd+Di4iIZAm/cXrx4Md5++20ZIzTXo8skOCtHnHzvVsYWHbbA2K79TJnXrl2TTCp17do1h50p09G88sorpgkLhwwZIvkVPGTIENPEhq+88orcoTq8ffv2CQBi4sSJFmdvnThxogAg9u3bJ1OEzuPBBx+0qqXmwQcflDtUh2dsPezo4Yithz0y+R6RIzNOvrdkyRJ4enoiIyMD77//PjIyMuDp6YmsrCxOvmeFv/3tbwButjLcOpeUca6q9vWoYyUlJQCAN954QzIaD7j5q3jZsmWSetSxkydP2rVeX2UwGPDMM890WueZZ55x2o7sTGpIMYwzYEZGRlocaRIZGSmpR5aJW27btdd+W/SdO9fkAKy9PcfbeJ37+9//jqampk7rNDU14e9//3svRWRfTGpIMYzD+9euXYvw8HDJUOTw8HCsXbtWUo8saz97tbe3NxYuXIh169Zh4cKF8Pb2tliPLEtISAAALFu2zOIyKK+//rqkHnWsfT8KFxcXTJ48GbNnz8bkyZMlrWC93V/S2WzevNmu9RxNt2YUJnJE8fHxCAgIQFZWlmQ2auDmUOQlS5YgICCAszN3ISIiAn/9618B3Jwoc+XKlR3Wo84lJCQgICAABw4cwH/9138hOTnZNM/K7t278eWXXyIgIIBJjRXar93X1tbW4e1PR1zjz5FUV1eb/vbz88Ndd92FlpYWuLu74/z586Zbzu3rORMmNaQo169fBwD4+vrivffew7Rp01BYWIjXXnsN169fN+2njll7e4638bqmVquxYcMGzJgxA7t27cLnn39u2me8lbdhwwbeMrHC1atX7Vqvr2o/z09DQ0OHazB2NB+Qo+PtJ1KMkpIS6PV6REREoF+/fnj++ecRHByM559/Hv3790dERAT0ej07ZXbB2snLOMmZbW5tPbx1mzpnXJDWXvX6KuOUDPaq52iY1JBiGJOVdevW4dtvv0VxcTHy8vJQXFyMqqoqvP/++5J6ZNnAgQNNfz/88MNIS0vDgw8+iLS0NDz88MMW65FlBoMBCxcuRFhYmFkr4fXr1xEWFoZFixY57UiT3mTtDLdOOxNuL/Hy8rJrPUfD20+kSGq1mv0UuunSpUumv0tKSiQXY+P6OrfWI8uM0wwA5iPJgP+sr1NaWsr3axeCg4PtWq+vunz5sl3rORomNaQYCQkJWL58OZYtW4b4+Hh8+eWXpjVNJkyYgDfeeMNUjzqe5fr77783/X3rsO32I3i+//77Dtcl40zXN509e9b0t6enp6SfQvvt9vXIMg7pto8ff/zRrvUcDZMaUoyEhAT4+/vjwIED8PX1lVxAjCNOONLkP7755htER0d3Wqe5ubnD7dzcXNPid7cqLy/HmDFjbj9IJ1dWVmb6e/LkyRaXSTDWmzNnjlxhOoU77rgDAODh4YGWlhZJwu3i4gJXV1e0tLSY6pFl1t7qdNZbokxqSDHUajX++7//G++8847ZxdjY6W3u3Ln8Jfd/IiIiUF5eblZuMBjw0EMP4YcffsDEiRMRFhaGzZs3Y+7cuTh16hQOHDiAO++8E3v27OnwXHK4900XLlwAcPOCnJ+fD51Oh7/+9a8ICgpCfn4+Bg8ejEuXLpnq9XWdrZFXX18P4GZiPXDgQNx///1obW2Fq6srjhw5gh9++MFUz1ILIlsPb4qMjMS5c+esqueUemHJBofBtZ+Uzbj2U1hYmMVVusPCwrj2k5U6Wlm6f//+Drs2jCOaMmWK2arclranTJkid6gOwfj91xMPfqfeFBERITkvAwcOFD/72c/EwIEDJeURERFyhyph7fWbLTWkGO07ZU6bNs1sojNjUz87ZXYtLS0NBQUFyMzMxHfffWcqDwgIwMqVK7nSuZViYmKwb98+AOb9k9pvx8TE9Gpcjqqj1kNA2oI4YcIEeHl5Ye/evUhKSsLVq1fx5ZdfdtqCyNbDmxobGyXbP/zwA4qKirqs5zR6JcVyEGypUbatW7cKACI5OdniisjJyckCgNi6datMETqf1tZW8eGHHwoA4sMPP2Qrl4327t1rVSvC3r175Q7VKRQUFAiVSmWxBVGlUrEF0Qq3nruOHv369ZM7VAm21FCfc/HiRQA3WxksrYicmpqK3bt3m+pR19RqtakVISYmhv2RbHTr+/B26/V1aWlpyM/Px8KFC02tsgAQGBiInJwctiC201H/pPaj7lQqlVmHa+MIR09PT6cc3cikhhTDOJOoVqvFM888I7lQtLW1YefOnZJ6RD2tfQfg9heMW7fZUdh6aWlpmD59OnJzc/HCCy/gww8/xLPPPsuE+xbWjG4UnUzZ8MMPP3T4fEce3cikhhTDuGr0nj17kJqaiqysLNPw2ezsbOzZs0dSj6in6XQ6ADdHP906mZmLiwt8fHxw6dIl6HQ6Dum2AVsQu9ZR/6QrV65g0qRJXT5///79GDBgQIev7aiY1JBT6WzIp5eXF4KDg3HHHXegvLwccXFxpn3BwcEYMWIEmpqa4OXlxSGf1CuMLTCXLl3C1KlTcc899+DatWvo168fqqqqsGvXLkk9Invp379/h60pDzzwAP75z392+NwHHngAP/3pT3sqtB7FpIacijVNqpYuEBcuXDCVjx071uLzHLlJlZxT+1+6xcXFpiQGkC450dEvYqKecOjQIYwdO9ZiYvPAAw/g0KFDMkRlH0xqyKl0NuTT6O9//zveffddSXJz1113ISMjAw8++GCnr01kT6NGjcKf/vQnANL+Crdujxo1qlfjIjp06BCuXLmCadOmYf/+/Zg0aRIKCwudPsFmUnObqqqq7Lrw14kTJyT/tRdvb2/cc889dn1NOXTWpGo0ZswYLFiwgB0JSXaDBw82/d3ZkhPt6xH1lgEDBmDVqlWIjo7GqlWrnD6hAZjU3Jaqqir85Cc/6ZHXnj17tt1f8+TJk4pIbKzBjoTkCKydwMxpJzojcjBMam6DsYVm69atGDFihF1e89q1azhz5gxCQ0Ml99xvx4kTJzB79mynXUqeyFkNHDgQAODq6oq77rpLMjtzaGgozp07h9bWVlM9Iro9TGrsYMSIEXbtYDphwgS7vRYRycfYEbO1tRVRUVFYvHixaemOPXv2mCaQ++c//4m5c+fKGCmRMjCpISK6TR1NNWBcWfonP/kJvv76a9P6Y8DNaQbuueceVFVVcWVpIjthUkOkQPbswM7O613raqqBkydPmpW1H5336aef4tNPPzWrw2kGiGzDpIZIYXqqAzs7r3eso6kGWlpaMHHiRPTr1w/e3t6ora017QsKCsLly5dx7do1HDhwAO7u7hZfVymcYaSokhLtvopJDZHC2LsDOzuvd62zqQYyMzPxzjvvwMvLC7Nnz8bWrVsxe/ZsFBUV4cqVK1i8eDFiY2N7OeLe5UwjRZ0h0WZLbMeY1JDD4C85+7JnB3Z2Xu++t99+GwDw7rvvYuvWrQBuJpyurq5YvHixab+SOcNIUWdJtNkS2zkmNeQQ+EuOlOztt9/G8uXLkZWVhVWrViEzMxPZ2dkWbzkpGUeK3j62xHaOSQ05BP6SI6Vzd3fHk08+iVWrVuHJJ5/scwkN2RdbYi1jUkMOhb/kyJE4wy1RwLluixL1JCY1t0HVeh2jB7ug36WTwAUXucPpUL9LJzF6sAtUrdflDoXIaTjTLVGAt0WJACY1t8XzSg2+fmEA8I8XgH/IHU3HRgD4+oUBOHGlBkCc3OFQD3OGZNsZEm1nuCUKOMdtUb4n7YfnsnPdSmrWr1+Pd955B7W1tbj33nuxevVqxMfHd1h///79yMzMxLFjxxAcHIxXXnkF8+bNk9QpKCjAa6+9hlOnTiEsLAy/+c1v8POf//y2jtvTrg8YhjEfXsGf/vQnjHDg+SROfPMNnnzySeROHSZ3KB3iB9V+nCHZdqZEm7dEbx/fk/bDc9k5m5OaHTt2ICMjA+vXr8eECRPw4YcfIjk5GcePH8ewYeYXzerqakydOhW/+MUvsHXrVnz55Zd48cUX4e/vjxkzZgAAdDodZs6cibfeegs///nP8dlnn+Gxxx7DgQMHMG7cuG4dtzcIV09U1LXh2h0/AYLvlyUGa1yra0NFXRuEq6fcoXSIH1T7cYZkm4m2/ThDss33pP3wXHbO5qRm1apVePbZZ/Hcc88BAFavXo0vvvgCGzZsQHZ2tln9Dz74AMOGDcPq1asB3PzVc/jwYeTk5JiSmtWrV+NnP/sZsrKyAABZWVnYv38/Vq9ejW3btnXruORcflD7YcyHV/Daa6/ZbRbV5uZmXLhwAcHBwfDw8Ljt16uursavf/1rh//Su9pyM4n98vQVXLuj7bZfr0dumdQamGjbiTMk287wA9AZfvwB/Hx3xaakpqWlBeXl5Xj11Vcl5UlJSSgrK7P4HJ1Oh6SkJEnZQw89hNzcXNy4cQNubm7Q6XRYsGCBWR1jItSd4wI3L2rNzc2mbb1e3+W/0RY//vgjAFhciO5WxjeOvVnzRrT3SIuecLzqDCrq2pD2yzfkDqVLAwb6yx1Cp4wLK/7iF7+QOZKueXt7yx1Ch2xJtI0JtL1Zk5A7Q7Jt7XdlT31PAl1/VzrD9yTAz3dXbEpqGhoaYDAYEBgYKCkPDAxEXV2dxefU1dVZrN/a2oqGhgYEBQV1WMf4mt05LgBkZ2fjjTd67iLpTG8uwLEvIKmpqQC6XpXY2CmyJ1jTIdQZhs7yXNqHMyXagGMn2870XenI35MAP99d6VZHYZVKJdkWQpiVdVX/1nJrXtPW42ZlZSEzM9O0rdfrMXTo0A7r28raNxcgb0sN4PgXED8/P9Otxc50tHCgJbY2q1rz/9EZ2Ptcdqd5Wgnnkp9v+7H2XMrZUgM4/nkE+Pnuik1JjZ+fH9RqtVnrSH19vVkritHgwYMt1nd1dcWgQYM6rWN8ze4cFwA8PDzs0peiI9a+uYz64qgHe+ts4UBLeM47Zsu57IvnkZ9v+7HlXPI82kdf/Xzb1KXf3d0d0dHRKCoqkpQXFRUhLs5yB7Xx48eb1d+7dy9iYmLg5ubWaR3ja3bnuERERNTHCBtt375duLm5idzcXHH8+HGRkZEhvLy8xJkzZ4QQQrz66qtizpw5pvqnT58W/fv3FwsWLBDHjx8Xubm5ws3NTeTn55vqfPnll0KtVovf/va34sSJE+K3v/2tcHV1FQcPHrT6uNZoamoSAERTU5Ot/2wiIiKSibXXb5uTGiGEWLdunQgJCRHu7u5izJgxYv/+/aZ9c+fOFZMmTZLULykpEaNHjxbu7u4iNDRUbNiwwew1P/30UzF8+HDh5uYmIiIiREFBgU3HtQaTGiIiIudj7fVbJcT/9drtA/R6PXx9fdHU1AQfHx+5wyEiIiIrWHv9dtxpMomIiIhswKSGiIiIFIFJDRERESkCkxoiIiJSBCY1REREpAhMaoiIiEgRmNQQERGRIjCpISIiIkVgUkNERESKYNMq3c7OOHmyXq+XORIiIiKylvG63dUiCH0qqbl8+TIAYOjQoTJHQkRERLa6fPkyfH19O9zfp9Z+amtrw4ULF+Dt7Q2VSiV3OBbp9XoMHToUZ8+e5fpUt4nn0j54Hu2H59J+eC7tw1nOoxACly9fRnBwMFxcOu4506daalxcXDBkyBC5w7CKj4+PQ7/BnAnPpX3wPNoPz6X98FzahzOcx85aaIzYUZiIiIgUgUkNERERKQKTGgfj4eGBZcuWwcPDQ+5QnB7PpX3wPNoPz6X98Fzah9LOY5/qKExERETKxZYaIiIiUgQmNURERKQITGqIiIhIEZjUEBERkSIwqXEQ//jHP5CSkoLg4GCoVCrs3LlT7pCcUnZ2Nh544AF4e3sjICAAqamp+J//+R+5w3JKGzZswH333WealGv8+PHYvXu33GE5vezsbKhUKmRkZMgditN5/fXXoVKpJI/BgwfLHZbTOn/+PGbPno1Bgwahf//+uP/++1FeXi53WLeFSY2DuHr1KkaNGoW1a9fKHYpT279/P375y1/i4MGDKCoqQmtrK5KSknD16lW5Q3M6Q4YMwW9/+1scPnwYhw8fxoMPPojp06fj2LFjcofmtP75z39i48aNuO++++QOxWnde++9qK2tNT2OHj0qd0hO6YcffsCECRPg5uaG3bt34/jx41i5ciXuuOMOuUO7LX1qmQRHlpycjOTkZLnDcHp79uyRbH/00UcICAhAeXk5fvrTn8oUlXNKSUmRbP/mN7/Bhg0bcPDgQdx7770yReW8rly5gieffBKbNm3C8uXL5Q7Habm6urJ1xg5+97vfYejQofjoo49MZaGhofIFZCdsqSFFa2pqAgDceeedMkfi3AwGA7Zv346rV69i/PjxcofjlH75y1/ikUcewZQpU+QOxalVVVUhODgYGo0Gjz/+OE6fPi13SE7pL3/5C2JiYvDoo48iICAAo0ePxqZNm+QO67YxqSHFEkIgMzMTEydORGRkpNzhOKWjR49iwIAB8PDwwLx58/DZZ59h5MiRcofldLZv346vv/4a2dnZcofi1MaNG4ctW7bgiy++wKZNm1BXV4e4uDg0NjbKHZrTOX36NDZs2IB77rkHX3zxBebNm4df/epX2LJli9yh3RbefiLFeumll/Dvf/8bBw4ckDsUpzV8+HAcOXIEly5dQkFBAebOnYv9+/czsbHB2bNnMX/+fOzduxeenp5yh+PU2t+ij4qKwvjx4xEWFobNmzcjMzNTxsicT1tbG2JiYrBixQoAwOjRo3Hs2DFs2LABTz31lMzRdR9bakiRXn75ZfzlL39BcXExhgwZInc4Tsvd3R3h4eGIiYlBdnY2Ro0ahTVr1sgdllMpLy9HfX09oqOj4erqCldXV+zfvx/vvfceXF1dYTAY5A7RaXl5eSEqKgpVVVVyh+J0goKCzH6cjBgxAjU1NTJFZB9sqSFFEULg5ZdfxmeffYaSkhJoNBq5Q1IUIQSam5vlDsOpTJ482WyEztNPP42IiAj8v//3/6BWq2WKzPk1NzfjxIkTiI+PlzsUpzNhwgSz6S5OnjyJkJAQmSKyDyY1DuLKlSv49ttvTdvV1dU4cuQI7rzzTgwbNkzGyJzLL3/5S+Tl5eHPf/4zvL29UVdXBwDw9fVFv379ZI7OuSxZsgTJyckYOnQoLl++jO3bt6OkpMRshBl1ztvb26xPl5eXFwYNGsS+XjZatGgRUlJSMGzYMNTX12P58uXQ6/WYO3eu3KE5nQULFiAuLg4rVqzAY489hkOHDmHjxo3YuHGj3KHdHkEOobi4WAAwe8ydO1fu0JyKpXMIQHz00Udyh+Z0nnnmGRESEiLc3d2Fv7+/mDx5sti7d6/cYSnCpEmTxPz58+UOw+nMnDlTBAUFCTc3NxEcHCzS0tLEsWPH5A7Laf31r38VkZGRwsPDQ0RERIiNGzfKHdJtUwkhhEz5FBEREZHdsKMwERERKQKTGiIiIlIEJjVERESkCExqiIiISBGY1BAREZEiMKkhIiIiRWBSQ0RERIrApIaIiIgUgUkNERERKQKTGiIiIlIEJjVERESkCExqiIiISBH+P/jz/6/FVsq1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(v_qul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_amats(speaker,layer,sevec):\n",
    "    attnmats=[]\n",
    "    fileList = os.listdir('/scratch/bs4283/auditory_data/data_20sample/tunnning_value')\n",
    "    ss_path = '/scratch/bs4283/auditory_data/data_20sample/tunnning_value'\n",
    "    fileList.sort(key=list_sort_tunning)\n",
    "    filename = fileList[layer]\n",
    "    filepath = os.path.join(ss_path,filename)\n",
    "    value = torch.load(filepath)\n",
    "    \n",
    "    for ii in range(6):\n",
    "        if ii == layer : \n",
    "            k=value[speaker,:]/(torch.max(torch.abs(value),0).values)\n",
    "            k=torch.unsqueeze(torch.unsqueeze(k,1),1)\n",
    "            k[k == torch.inf] = 0 \n",
    "            k[k == -torch.inf] = 0 \n",
    "            k = torch.from_numpy(np.nan_to_num(k.cpu().numpy())).to(device)\n",
    "            \n",
    "            if ii == 0:\n",
    "                amat = torch.ones([64, 96, 64]).to(device) + torch.tile(k,[1,96,64]).to(device) *sevec\n",
    "                attnmats.append(amat)\n",
    "            elif ii == 1:\n",
    "                amat = torch.ones([128, 48, 32]).to(device)  + torch.tile(k,[1,48,32]).to(device) *sevec\n",
    "                attnmats.append(amat)\n",
    "            elif ii == 2:\n",
    "                amat = torch.ones([256, 24, 16]).to(device)  + torch.tile(k,[1,24,16]).to(device) *sevec\n",
    "                attnmats.append(amat)\n",
    "            elif ii == 3:\n",
    "                amat = torch.ones([256, 24, 16]).to(device)  + torch.tile(k,[1,24,16]).to(device) *sevec\n",
    "                attnmats.append(amat)\n",
    "            elif ii == 4:\n",
    "                amat = torch.ones([512, 12, 8]).to(device)  + torch.tile(k,[1,12,8]).to(device) *sevec\n",
    "                attnmats.append(amat)\n",
    "            elif ii == 5:\n",
    "                amat = torch.ones([512, 12, 8]).to(device)  + torch.tile(k,[1,12,8]).to(device) *sevec\n",
    "                attnmats.append(amat)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if ii == 0:\n",
    "                amat = torch.ones([64, 96, 64]).to(device) \n",
    "                attnmats.append(amat)\n",
    "            elif ii == 1:\n",
    "                amat = torch.ones([128, 48, 32]).to(device) \n",
    "                attnmats.append(amat)\n",
    "            elif ii == 2:\n",
    "                amat = torch.ones([256, 24, 16]).to(device) \n",
    "                attnmats.append(amat)\n",
    "            elif ii == 3:\n",
    "                amat = torch.ones([256, 24, 16]).to(device) \n",
    "                attnmats.append(amat)\n",
    "            elif ii == 4:\n",
    "                amat = torch.ones([512, 12, 8]).to(device) \n",
    "                attnmats.append(amat)\n",
    "            elif ii == 5:\n",
    "                amat = torch.ones([512, 12, 8]).to(device) \n",
    "                attnmats.append(amat)\n",
    "    return attnmats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16ish(nn.Module):\n",
    "    def __init__(self,binary_weight,binary_bias,tunning):\n",
    "        super(VGG16ish, self).__init__()\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        self.tunning = tunning\n",
    "        self.binary_weight = binary_weight.to(device)\n",
    "        self.binary_bias = binary_bias.to(device)\n",
    "        base_model = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
    "        model_list = list(base_model.children())\n",
    "        self.model_layer0 = model_list[0][0:2]\n",
    "        self.model_layer1 = model_list[0][2:5]\n",
    "        self.model_layer2 = model_list[0][5:8]\n",
    "        self.model_layer3 = model_list[0][8:10]\n",
    "        self.model_layer4 = model_list[0][10:13]\n",
    "        self.model_layer5 = model_list[0][13:15]\n",
    "        self.model_layer6 = model_list[0][15] \n",
    "        self.linear1 = model_list[1]\n",
    "        self.linear2 = nn.Linear(128,1)\n",
    "        self.linear2.weight = nn.Parameter(self.binary_weight)\n",
    "        self.linear2.bias = nn.Parameter(self.binary_bias)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model_layer0(x)\n",
    "        out = torch.mul(out,self.tunning[0])\n",
    "        out = self.model_layer1(out)\n",
    "        out = torch.mul(out,self.tunning[1])\n",
    "        out = self.model_layer2(out)\n",
    "        out = torch.mul(out,self.tunning[2])\n",
    "        out = self.model_layer3(out)\n",
    "        out = torch.mul(out,self.tunning[3])\n",
    "        out = self.model_layer4(out)\n",
    "        out = torch.mul(out,self.tunning[4])\n",
    "        out = self.model_layer5(out)\n",
    "        out = torch.mul(out,self.tunning[5])\n",
    "        out = self.model_layer6(out)\n",
    "        out = torch.transpose(out, 1, 3)\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.contiguous().view(x.size(0), -1)\n",
    "        \n",
    "        out = self.linear1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import vggish_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort_data(x : str):\n",
    "    if '.' in x:\n",
    "        # 将文件名字用_进行分割\n",
    "        x = x.rpartition('.')\n",
    "        # 将x用.进行分割，最后拿到数字\n",
    "        if x[0][1] == '-':      \n",
    "            x = x[0][0]\n",
    "        else:\n",
    "            x=x[0][0:2]\n",
    "    else:\n",
    "        x = 0\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = 2\n",
    "#layer = 5 \n",
    "astrgs=np.arange(0,1.,.5)\n",
    "data_num = 75\n",
    "data_folder = '/scratch/bs4283/auditory_data/data_20sample/test_voice_20'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 0\n",
    "fileList_data = os.listdir('/scratch/bs4283/auditory_data/data_20sample/combine_test_20')\n",
    "fileList_data.sort(key=list_sort_data)\n",
    "sub = torch.arange(9000)\n",
    "sub = sub.numpy()\n",
    "sub_cat = torch.arange(cat*150,(cat+1)*150,1)\n",
    "sub_cat = sub_cat.numpy()\n",
    "sub_diff = np.setdiff1d(sub,sub_cat)\n",
    "r1 = torch.randperm(150)\n",
    "r2 = torch.randperm(8850)\n",
    "data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]\n",
    "data_neg = np.array(fileList_data)[sub_diff[r2.numpy()]]\n",
    "poi_data = torch.tensor([]).to(device)\n",
    "neg_data = torch.tensor([]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in range(data_num):\n",
    "    poi_path = os.path.join(data_folder,data_poi[kk])\n",
    "    p = vggish_input.wavfile_to_examples(poi_path).to(device)\n",
    "    poi_data = torch.cat([poi_data,p])\n",
    "\n",
    "\n",
    "orde = -1\n",
    "while neg_data.size(dim=0) < 75:\n",
    "    orde = orde + 1 \n",
    "    filename = data_neg[orde].rpartition('.')\n",
    "    if int(filename[0][3:5]) == cat+1:\n",
    "           continue\n",
    "    neg_path = os.path.join(data_folder,data_neg[orde])\n",
    "    n = vggish_input.wavfile_to_examples(neg_path).to(device)\n",
    "    neg_data = torch.cat([neg_data,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load(binary_weight)\n",
    "bin_b = torch.load(binary_bias)[cat]\n",
    "bin_w = w[cat,:]\n",
    "bin_w = torch.unsqueeze(bin_w,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = np.ones([2,6])\n",
    "nr = np.ones([2,6])\n",
    "for jj in range(6):\n",
    "    at = -1\n",
    "    for ast in astrgs:\n",
    "        at = at+1\n",
    "        t = make_amats(cat,jj,ast)\n",
    "        model_v = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t)            \n",
    "        model_v.eval()\n",
    "        p_result = model_v(poi_data)\n",
    "        n_result  = model_v(neg_data)\n",
    "        p_rate = torch.sum(p_result>0.5).cpu().numpy()/75\n",
    "        n_rate = torch.sum(n_result<0.5).cpu().numpy()/75\n",
    "        pr[at,jj] = p_rate\n",
    "        nr[at,jj] = n_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(sub_list[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = torch.tensor([1,2,3,4,5,6,8,10,11,12,13,28,36,43,47,52,56,57,58,59])-1\n",
    "cat_s = -1 \n",
    "for cat in sub_list:\n",
    "    cat_s = cat_s + 1 \n",
    "    fileList_data = os.listdir('/scratch/bs4283/auditory_data/data_20sample/combine_test_20')\n",
    "    fileList_data.sort(key=list_sort_data)\n",
    "    sub = torch.arange(3000)\n",
    "    sub = sub.numpy()\n",
    "    sub_cat = torch.arange(cat_s*150,(cat_s+1)*150,1)\n",
    "    sub_cat = sub_cat.numpy()\n",
    "    sub_diff = np.setdiff1d(sub,sub_cat)\n",
    "    r1 = torch.randperm(150)\n",
    "    r2 = torch.randperm(2850)\n",
    "    data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]\n",
    "    data_neg = np.array(fileList_data)[sub_diff[r2.numpy()]]\n",
    "    poi_data = torch.tensor([]).to(device)\n",
    "    neg_data = torch.tensor([]).to(device)\n",
    "    \n",
    "    for kk in range(data_num):\n",
    "        poi_path = os.path.join(data_folder,data_poi[kk])\n",
    "        p = vggish_input.wavfile_to_examples(poi_path).to(device)\n",
    "        poi_data = torch.cat([poi_data,p])\n",
    "\n",
    "\n",
    "    orde = -1\n",
    "    while neg_data.size(dim=0) < 75:\n",
    "        orde = orde + 1 \n",
    "        filename = data_neg[orde].rpartition('.')\n",
    "        if int(filename[0][3:5]) == cat+1:\n",
    "               continue\n",
    "        neg_path = os.path.join(data_folder,data_neg[orde])\n",
    "        n = vggish_input.wavfile_to_examples(neg_path).to(device)\n",
    "        neg_data = torch.cat([neg_data,n])\n",
    "        \n",
    "        \n",
    "    w = torch.load(binary_weight)\n",
    "    bin_b = torch.load(binary_bias)[cat_s]\n",
    "    bin_w = w[cat_s,:]\n",
    "    bin_w = torch.unsqueeze(bin_w,0)\n",
    "    \n",
    "    pr = np.ones([2,6])\n",
    "    nr = np.ones([2,6])\n",
    "    for jj in range(6):\n",
    "        at = -1\n",
    "        for ast in astrgs:\n",
    "            at = at+1\n",
    "            t = make_amats(cat_s,jj,ast)\n",
    "            model_v = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t)            \n",
    "            model_v.eval()\n",
    "            p_result = model_v(poi_data)\n",
    "            n_result  = model_v(neg_data)\n",
    "            p_rate = torch.sum(p_result>0.5).cpu().numpy()/75\n",
    "            n_rate = torch.sum(n_result<0.5).cpu().numpy()/75\n",
    "            pr[at,jj] = p_rate\n",
    "            nr[at,jj] = n_rate\n",
    "    np.save('/scratch/bs4283/auditory_data/data_20sample/result2/cat'+ str(cat.numpy()) + '_poi.npy',pr)\n",
    "    np.save('/scratch/bs4283/auditory_data/data_20sample/result2/cat'+ str(cat.numpy()) + '_neg.npy',nr)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for raw test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort_data(x : str):\n",
    "    if '.' in x:\n",
    "        # 将文件名字用_进行分割\n",
    "        x = x.rpartition('.')\n",
    "        # 将x用.进行分割，最后拿到数字\n",
    "        if x[0][1] == '-':      \n",
    "            x = x[0][0]\n",
    "        else:\n",
    "            x=x[0][2:4]\n",
    "    else:\n",
    "        x = 0\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n",
      "Using cache found in /home/bs4283/.cache/torch/hub/harritaylor_torchvggish_master\n"
     ]
    }
   ],
   "source": [
    "sub_list = torch.tensor([1,2,3,4,5,6,8,10,11,12,13,28,36,43,47,52,56,57,58,59])-1\n",
    "cat_s = -1 \n",
    "for cat in sub_list:\n",
    "    cat_s = cat_s + 1 \n",
    "    fileList_data = os.listdir('/scratch/bs4283/auditory_data/data_20sample/test_voice_20')\n",
    "    fileList_data.sort(key=list_sort_data)\n",
    "    sub = torch.arange(3000)\n",
    "    sub = sub.numpy()\n",
    "    sub_cat = torch.arange(cat_s*150,(cat_s+1)*150,1)\n",
    "    sub_cat = sub_cat.numpy()\n",
    "    sub_diff = np.setdiff1d(sub,sub_cat)\n",
    "    r1 = torch.randperm(150)\n",
    "    r2 = torch.randperm(2850)\n",
    "    data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]\n",
    "    data_neg = np.array(fileList_data)[sub_diff[r2.numpy()]]\n",
    "    poi_data = torch.tensor([]).to(device)\n",
    "    neg_data = torch.tensor([]).to(device)\n",
    "    \n",
    "    for kk in range(data_num):\n",
    "        poi_path = os.path.join(data_folder,data_poi[kk])\n",
    "        p = vggish_input.wavfile_to_examples(poi_path).to(device)\n",
    "        poi_data = torch.cat([poi_data,p])\n",
    "\n",
    "\n",
    "    orde = -1\n",
    "    while neg_data.size(dim=0) < 75:\n",
    "        orde = orde + 1 \n",
    "        filename = data_neg[orde].rpartition('.')\n",
    " #       if int(filename[0][3:5]) == cat+1:\n",
    " #             continue\n",
    "        neg_path = os.path.join(data_folder,data_neg[orde])\n",
    "        n = vggish_input.wavfile_to_examples(neg_path).to(device)\n",
    "        neg_data = torch.cat([neg_data,n])\n",
    "        \n",
    "        \n",
    "    w = torch.load(binary_weight)\n",
    "    bin_b = torch.load(binary_bias)[cat_s]\n",
    "    bin_w = w[cat_s,:]\n",
    "    bin_w = torch.unsqueeze(bin_w,0)\n",
    "    \n",
    "    pr = np.ones([2,6])\n",
    "    nr = np.ones([2,6])\n",
    "    for jj in range(6):\n",
    "        at = -1\n",
    "        for ast in astrgs:\n",
    "            at = at+1\n",
    "            t = make_amats(cat_s,jj,ast)\n",
    "            model_v = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t)            \n",
    "            model_v.eval()\n",
    "            p_result = model_v(poi_data)\n",
    "            n_result  = model_v(neg_data)\n",
    "            p_rate = torch.sum(p_result>0.5).cpu().numpy()/75\n",
    "            n_rate = torch.sum(n_result<0.5).cpu().numpy()/75\n",
    "            pr[at,jj] = p_rate\n",
    "            nr[at,jj] = n_rate\n",
    "    np.save('/scratch/bs4283/auditory_data/data_20sample/result_raw_data/cat'+ str(cat.numpy()) + '_poi.npy',pr)\n",
    "    np.save('/scratch/bs4283/auditory_data/data_20sample/result_raw_data/cat'+ str(cat.numpy()) + '_neg.npy',nr)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr+nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in torch.arange(2,20):\n",
    "    pr = np.ones([2,6])\n",
    "    nr = np.ones([2,6])\n",
    "    sub_cat = torch.arange(cat*150,(cat+1)*150,1)\n",
    "    sub_cat = sub_cat.numpy()\n",
    "    sub_diff = np.setdiff1d(sub,sub_cat)\n",
    "    r1 = torch.randperm(150)[0:data_num]\n",
    "    r2 = torch.randperm(8850)[0:data_num]\n",
    "    data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]\n",
    "    data_neg = np.array(fileList_data)[sub_diff[r2.numpy()]]\n",
    "    poi_data = torch.tensor([]).to(device)\n",
    "    neg_data = torch.tensor([]).to(device)\n",
    "    for kk in range(data_num):\n",
    "        poi_path = os.path.join(data_folder,data_poi[kk])\n",
    "        neg_path = os.path.join(data_folder,data_neg[kk])\n",
    "        p = vggish_input.wavfile_to_examples(poi_path).to(device)\n",
    "        n = vggish_input.wavfile_to_examples(neg_path).to(device)\n",
    "        poi_data = torch.cat([poi_data,p])\n",
    "        neg_data = torch.cat([neg_data,n])\n",
    "    w = torch.load(binary_weight)\n",
    "    bin_b = torch.load(binary_bias)[cat]\n",
    "    bin_w = w[cat,:]\n",
    "    bin_w = torch.unsqueeze(bin_w,0)\n",
    "    \n",
    "    for jj in range(6):\n",
    "        at = -1\n",
    "        for ast in astrgs:\n",
    "            at = at+1\n",
    "            t = make_amats(cat,jj,ast)\n",
    "            model_v = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t)\n",
    "            model_v.eval()\n",
    "            p_result = model_v(poi_data)\n",
    "            n_result  = model_v(neg_data)\n",
    "\n",
    "            p_rate = torch.sum(p_result>0.5).cpu().numpy()/75\n",
    "            n_rate = torch.sum(n_result<0.5).cpu().numpy()/75\n",
    "            pr[at,jj] = p_rate\n",
    "            nr[at,jj] = n_rate\n",
    "    np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cat) + '_poi.npy',pr)\n",
    "    np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cat) + '_neg.npy',nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load(binary_weight)\n",
    "bin_b = torch.load(binary_bias)[0]\n",
    "bin_w = w[0,:]\n",
    "bin_w = torch.unsqueeze(bin_w,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = make_amats(0,0,0)\n",
    "model = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort_data_try(x : str):\n",
    "    if '.' in x:\n",
    "        # 将文件名字用_进行分割\n",
    "        x = x.rpartition('.')\n",
    "        # 将x用.进行分割，最后拿到数字\n",
    "        if x[0][1] == '-':      \n",
    "            x = x[0][0]\n",
    "        else:\n",
    "            x=x[0][2:4]\n",
    "    else:\n",
    "        x = 0\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = '/scratch/bs4283/auditory_data/data/re_test_voice/'\n",
    "ft_data = os.listdir(f_path)\n",
    "ft_data.sort(key=list_sort_data_try)\n",
    "sub1_data = torch.tensor([]).to(device)\n",
    "for ii in range(300):\n",
    "    sd = os.path.join(f_path,ft_data[ii])\n",
    "    n = vggish_input.wavfile_to_examples(sd).to(device)\n",
    "    sub1_data = torch.cat([sub1_data,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = model(sub1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_p = rr[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_n = rr[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(rr_p>0.5)/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(rr_n<0.5)/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load(binary_weight)\n",
    "bin_b = torch.load(binary_bias)[1]\n",
    "bin_w = w[1,:]\n",
    "bin_w = torch.unsqueeze(bin_w,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = make_amats(0,0,0)\n",
    "model2 = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr2 = model2(sub1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr2_p = rr2[150:]; rr2_n = rr2[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(rr2_p>0.5)/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(rr2_n<0.5)/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = model(sub1_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas = -1\n",
    "for cat in range(1):\n",
    "    cas = cas+1\n",
    "    pr = np.ones([2,6])\n",
    "    nr = np.ones([2,6])\n",
    "    sub_cat = torch.arange(cat*150,(cat+1)*150,1)\n",
    "    sub_cat = sub_cat.numpy()\n",
    "    sub_diff = np.setdiff1d(sub,sub_cat)\n",
    "    r1 = torch.randperm(150)[0:data_num]\n",
    "    r2 = torch.randperm(8850)[0:data_num]\n",
    "    data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]\n",
    "    data_neg = np.array(fileList_data)[sub_diff[r2.numpy()]]\n",
    "    poi_data = torch.tensor([]).to(device)\n",
    "    neg_data = torch.tensor([]).to(device)\n",
    "    for kk in range(data_num):\n",
    "        poi_path = os.path.join(data_folder,data_poi[kk])\n",
    "        neg_path = os.path.join(data_folder,data_neg[kk])\n",
    "        p = vggish_input.wavfile_to_examples(poi_path).to(device)\n",
    "        n = vggish_input.wavfile_to_examples(neg_path).to(device)\n",
    "        poi_data = torch.cat([poi_data,p])\n",
    "        neg_data = torch.cat([neg_data,n])\n",
    "    w = torch.load(binary_weight)\n",
    "    bin_b = torch.load(binary_bias)[cat]\n",
    "    bin_w = w[cat,:]\n",
    "    bin_w = torch.unsqueeze(bin_w,0)\n",
    "    \n",
    "    for jj in range(6):\n",
    "        at = -1\n",
    "        for ast in astrgs:\n",
    "            at = at+1\n",
    "            t = make_amats(cat,jj,ast)\n",
    "            model_v = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t)\n",
    "            model_v.eval()\n",
    "            p_result = model_v(poi_data)\n",
    "            n_result  = model_v(neg_data)\n",
    "\n",
    "            p_rate = torch.sum(p_result>0.5).cpu().numpy()/75\n",
    "            n_rate = torch.sum(n_result<0.5).cpu().numpy()/75\n",
    "            pr[at,jj] = p_rate\n",
    "            nr[at,jj] = n_rate\n",
    "    np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cas) + '_poi_new.npy',pr)\n",
    "    np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cas) + '_neg_new.npy',nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single subject train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 0\n",
    "sub_cat = torch.arange(cat*150,(cat+1)*150,1)\n",
    "sub = sub.numpy()\n",
    "sub_cat = sub_cat.numpy()\n",
    "sub_diff = np.setdiff1d(sub,sub_cat)\n",
    "r1 = torch.randperm(150)[0:data_num]\n",
    "r2 = torch.randperm(8850)[0:data_num]\n",
    "data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]\n",
    "data_neg = np.array(fileList_data)[sub_diff[r2.numpy()]]\n",
    "poi_data = torch.tensor([]).to(device)\n",
    "neg_data = torch.tensor([]).to(device)\n",
    "for kk in range(data_num):\n",
    "    poi_path = os.path.join(data_folder,data_poi[kk])\n",
    "    neg_path = os.path.join(data_folder,data_neg[kk])\n",
    "    p = vggish_input.wavfile_to_examples(poi_path).to(device)\n",
    "    n = vggish_input.wavfile_to_examples(neg_path).to(device)\n",
    "    poi_data = torch.cat([poi_data,p])\n",
    "    neg_data = torch.cat([neg_data,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load(binary_weight)\n",
    "bin_b = torch.load(binary_bias)[cat]\n",
    "bin_w = w[cat,:]\n",
    "bin_w = torch.unsqueeze(bin_w,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in torch.arange(2,20):\n",
    "    pr = np.ones([2,6])\n",
    "    nr = np.ones([2,6])\n",
    "    sub_cat = torch.arange(cat*150,(cat+1)*150,1)\n",
    "    sub_cat = sub_cat.numpy()\n",
    "    sub_diff = np.setdiff1d(sub,sub_cat)\n",
    "    r1 = torch.randperm(150)[0:data_num]\n",
    "    r2 = torch.randperm(8850)[0:data_num]\n",
    "    data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]\n",
    "    data_neg = np.array(fileList_data)[sub_diff[r2.numpy()]]\n",
    "    poi_data = torch.tensor([]).to(device)\n",
    "    neg_data = torch.tensor([]).to(device)\n",
    "    for kk in range(data_num):\n",
    "        poi_path = os.path.join(data_folder,data_poi[kk])\n",
    "        neg_path = os.path.join(data_folder,data_neg[kk])\n",
    "        p = vggish_input.wavfile_to_examples(poi_path).to(device)\n",
    "        n = vggish_input.wavfile_to_examples(neg_path).to(device)\n",
    "        poi_data = torch.cat([poi_data,p])\n",
    "        neg_data = torch.cat([neg_data,n])\n",
    "    w = torch.load(binary_weight)\n",
    "    bin_b = torch.load(binary_bias)[cat]\n",
    "    bin_w = w[cat,:]\n",
    "    bin_w = torch.unsqueeze(bin_w,0)\n",
    "    \n",
    "    for jj in range(6):\n",
    "        at = -1\n",
    "        for ast in astrgs:\n",
    "            at = at+1\n",
    "            t = make_amats(cat,jj,ast)\n",
    "            model_v = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t)\n",
    "            model_v.eval()\n",
    "            p_result = model_v(poi_data)\n",
    "            n_result  = model_v(neg_data)\n",
    "\n",
    "            p_rate = torch.sum(p_result>0.5).cpu().numpy()/75\n",
    "            n_rate = torch.sum(n_result<0.5).cpu().numpy()/75\n",
    "            pr[at,jj] = p_rate\n",
    "            nr[at,jj] = n_rate\n",
    "    np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cat) + '_poi.npy',pr)\n",
    "    np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cat) + '_neg.npy',nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cat) + '_poi.npy',pr)\n",
    "np.save('/scratch/bs4283/auditory_data/result/cat'+ str(cat) + '_neg.npy',nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = make_amats(cat,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v = VGG16ish(binary_weight = bin_w,binary_bias = bin_b ,tunning = t)\n",
    "model_v.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_result = model_v(poi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_result  = model_v(neg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "astrgsTry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rate = torch.sum(p_result>0.5).cpu().numpy()/75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort(x : str):\n",
    "    if '.' in x:\n",
    "        # 将文件名字用_进行分割\n",
    "        x = x.rpartition('_')\n",
    "        # 将x用.进行分割，最后拿到数字\n",
    "        x = x[0][2:4]\n",
    "    else:\n",
    "        x = 0\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kks = torch.tensor([])\n",
    "ss_path = '/scratch/bs4283/auditory_data/data/re_train_voice/training_data'\n",
    "fileList = os.listdir('/scratch/bs4283/auditory_data/data/re_train_voice/training_data')\n",
    "fileList.sort(key=list_sort)\n",
    "for filename in fileList[cat*200:(cat*200+75)]:\n",
    "    filepath = os.path.join(ss_path,filename)\n",
    "    vid = vggish_input.wavfile_to_examples(filepath)\n",
    "    kks = torch.cat([kks,vid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg=model_v(kks.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('01') == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = os.listdir('/scratch/bs4283/auditory_data/data/re_train_voice/training_data')\n",
    "fileList.sort(key=list_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import vggish_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = vggish_input.wavfile_to_examples('/scratch/bs4283/auditory_data/data/re_train_voice/training_data/6_01_39.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kks = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kks = torch.cat([kks,vid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = torch.ones([75,128]).to(device)\n",
    "linear2 = nn.Linear(128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight = nn.Parameter(bin_w.to(device))\n",
    "linear2.bias = nn.Parameter(bin_b.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2(oo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd=torch.unsqueeze(bin_w,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poi = np.array(fileList_data)[sub_cat[r1.numpy()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.array(fileList_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(data_folder,cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList_data[np.array([1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poi = fileList_data[sub_cat[list(r1.numpy())].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poi = fileList_data[sub_cat[list(r1.numpy())]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poi = fileList_data[sub_cat[r1.numpy()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poi = fileList_data[sub_cat[r1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = torch.randperm(150)[0:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = torch.randperm(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_layer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cat = torch.arange(cat*150,(cat+1)*150,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_amats(1,1,1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(1,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=torch.cat([sub,sub_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.tensor([0,2,3,4])\n",
    "sds = torch.tensor([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sds)-set(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = set(sub)-set(sub_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "attnmats=[]\n",
    "fileList = os.listdir('/scratch/bs4283/auditory_data/data/tunning_value')\n",
    "ss_path = '/scratch/bs4283/auditory_data/data/tunning_value'\n",
    "fileList.sort(key=list_sort_tunning)\n",
    "filename = fileList[layer]\n",
    "filepath = os.path.join(ss_path,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = 1\n",
    "k=value[speaker,:]/(torch.max(torch.abs(value),0).values)\n",
    "k=torch.unsqueeze(torch.unsqueeze(k,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[k == torch.inf] = 0 \n",
    "k[k == -torch.inf] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh = torch.tile(k,[1,48,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = torch.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_amats(1,1,1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
    "model.postprocess = False\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.load('/scratch/bs4283/auditory_data/data/tunning_value/tunning_value1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=l[1,:]/(torch.max(torch.abs(l),0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(torch.abs(l),0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/scratch/bs4283/auditory_data/data/tunning_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/scratch/bs4283/auditory_data/data/tunning_value/tunning_value2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 'tunning_value2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rpartition('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = c.rpartition('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.rpartition('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fileList = os.listdir('/scratch/bs4283/auditory_data/data/tunning_value')\n",
    "    fileList.sort(key=list_sort_tunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amat = torch.ones([64, 96, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attnmats=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attnmats.append(amat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attnmats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=torch.unsqueeze(torch.unsqueeze(k,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[k == torch.inf] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=torch.unsqueeze(torch.unsqueeze(k,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tile(k,[1,96,64]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "linear2 = nn.Linear(128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.load('/scratch/bs4283/auditory_data/data/re_train_voice/binary_weight.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight=nn.Parameter(c[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
