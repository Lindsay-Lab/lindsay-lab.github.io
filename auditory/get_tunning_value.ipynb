{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import hub\n",
    "from script import vggish_input, vggish_params\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort(x : str):\n",
    "    if '.' in x:\n",
    "\n",
    "        x = x.rpartition('_')\n",
    "\n",
    "        x = x[0][2:4]\n",
    "    else:\n",
    "        x = 0\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_path = '/scratch/bs4283/auditory_data/data_20sample/tunning_voice_20'\n",
    "fileList = os.listdir('/scratch/bs4283/auditory_data/data_20sample/tunning_voice_20')\n",
    "fileList.sort(key=list_sort)\n",
    "value_1 = torch.tensor([])\n",
    "input_v = torch.tensor([])\n",
    "for filename in fileList:\n",
    "    filepath = os.path.join(ss_path,filename)\n",
    "    vid = vggish_input.wavfile_to_examples(filepath)\n",
    "    input_v = torch.cat([input_v,vid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Get_tunning(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Get_tunning, self).__init__()\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        base_model = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
    "        model_list = list(base_model.children())\n",
    "        self.model_layer0 = model_list[0][0:2]\n",
    "        self.model_layer1 = model_list[0][2:5]\n",
    "        self.model_layer2 = model_list[0][5:8]\n",
    "        self.model_layer3 = model_list[0][8:10]\n",
    "        self.model_layer4 = model_list[0][10:13]\n",
    "        self.model_layer5 = model_list[0][13:15]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.model_layer0(x)\n",
    "        out2 = self.model_layer1(out1)\n",
    "        out3 = self.model_layer2(out2)\n",
    "        out4 = self.model_layer3(out3)\n",
    "        out5 = self.model_layer4(out4)\n",
    "        out6 = self.model_layer5(out5)\n",
    "       \n",
    "        return out1,out2,out3,out4,out5,out6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tunning = Get_tunning().to(device)\n",
    "model_tunning.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_v,'/scratch/bs4283/auditory_data/data_20sample/tunning_voice_20/tunning_input.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning1 = torch.tensor([]).to(device)\n",
    "tunning2 = torch.tensor([]).to(device)\n",
    "tunning3 = torch.tensor([]).to(device)\n",
    "tunning4 = torch.tensor([]).to(device)\n",
    "tunning5 = torch.tensor([]).to(device)\n",
    "tunning6 = torch.tensor([]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(20):\n",
    "    input_v1 = input_v[(x*150):((x+1)*150),:,:,:].to(device)\n",
    "    y1,y2,y3,y4,y5,y6=model_tunning(input_v1)\n",
    "    value1 = torch.mean(y1,[2,3])\n",
    "    c1 = torch.mean(value1,0)\n",
    "    tunning1 = torch.cat([tunning1,torch.unsqueeze(c1,0)])\n",
    "    \n",
    "    value2 = torch.mean(y2,[2,3])\n",
    "    c2 = torch.mean(value2,0)\n",
    "    tunning2 = torch.cat([tunning2,torch.unsqueeze(c2,0)])\n",
    "    \n",
    "    value3 = torch.mean(y3,[2,3])\n",
    "    c3 = torch.mean(value3,0)\n",
    "    tunning3 = torch.cat([tunning3,torch.unsqueeze(c3,0)])\n",
    "    \n",
    "    value4 = torch.mean(y4,[2,3])\n",
    "    c4 = torch.mean(value4,0)\n",
    "    tunning4 = torch.cat([tunning4,torch.unsqueeze(c4,0)])\n",
    "    \n",
    "    value5 = torch.mean(y5,[2,3])\n",
    "    c5 = torch.mean(value5,0)\n",
    "    tunning5 = torch.cat([tunning5,torch.unsqueeze(c5,0)])\n",
    "    \n",
    "    value6 = torch.mean(y6,[2,3])\n",
    "    c6 = torch.mean(value6,0)\n",
    "    tunning6 = torch.cat([tunning6,torch.unsqueeze(c6,0)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_v1 = input_v[0:150,:,:,:].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model_tunning(input_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1,y2,y3,y4,y5,y6=model_tunning(input_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning = torch.tensor([]).to(device)\n",
    "value1 = torch.mean(y1,[2,3])\n",
    "c1 = torch.mean(value1,0)\n",
    "tunning1 = torch.cat([tunning1,torch.unsqueeze(c1,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning = torch.cat([tunning,torch.unsqueeze(c,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tunning1,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value1.pt')\n",
    "torch.save(tunning2,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value2.pt')\n",
    "torch.save(tunning3,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value3.pt')\n",
    "torch.save(tunning4,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value4.pt')\n",
    "torch.save(tunning5,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value5.pt')\n",
    "torch.save(tunning6,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning1 = torch.load('/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value1.pt')\n",
    "tunning2 = torch.load('/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value2.pt')\n",
    "tunning3 = torch.load('/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value3.pt')\n",
    "tunning4 = torch.load('/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value4.pt')\n",
    "tunning5 = torch.load('/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value5.pt')\n",
    "tunning6 = torch.load('/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/tunning_value6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning1_mean = torch.mean(tunning1,0)\n",
    "tunning2_mean = torch.mean(tunning2,0)\n",
    "tunning3_mean = torch.mean(tunning3,0)\n",
    "tunning4_mean = torch.mean(tunning4,0)\n",
    "tunning5_mean = torch.mean(tunning5,0)\n",
    "tunning6_mean = torch.mean(tunning6,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_tun1 = tunning1 - tunning1_mean\n",
    "diff_tun2 = tunning2 - tunning2_mean\n",
    "diff_tun3 = tunning3 - tunning3_mean\n",
    "diff_tun4 = tunning4 - tunning4_mean\n",
    "diff_tun5 = tunning5 - tunning5_mean\n",
    "diff_tun6 = tunning6 - tunning6_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning1_std = torch.std(tunning1,0)\n",
    "tunning2_std = torch.std(tunning2,0)\n",
    "tunning3_std = torch.std(tunning3,0)\n",
    "tunning4_std = torch.std(tunning4,0)\n",
    "tunning5_std = torch.std(tunning5,0)\n",
    "tunning6_std = torch.std(tunning6,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun1 = diff_tun1/tunning1_std\n",
    "tun2 = diff_tun2/tunning2_std\n",
    "tun3 = diff_tun3/tunning3_std\n",
    "tun4 = diff_tun4/tunning4_std\n",
    "tun5 = diff_tun5/tunning5_std\n",
    "tun6 = diff_tun6/tunning6_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun1 = torch.from_numpy(np.nan_to_num(tun1.cpu().detach().numpy())).to(device)\n",
    "tun2 = torch.from_numpy(np.nan_to_num(tun2.cpu().detach().numpy())).to(device)\n",
    "tun3 = torch.from_numpy(np.nan_to_num(tun3.cpu().detach().numpy())).to(device)\n",
    "tun4 = torch.from_numpy(np.nan_to_num(tun4.cpu().detach().numpy())).to(device)\n",
    "tun5 = torch.from_numpy(np.nan_to_num(tun5.cpu().detach().numpy())).to(device)\n",
    "tun6 = torch.from_numpy(np.nan_to_num(tun6.cpu().detach().numpy())).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tun1,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/normalize/tunning_value1.pt')\n",
    "torch.save(tun2,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/normalize/tunning_value2.pt')\n",
    "torch.save(tun3,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/normalize/tunning_value3.pt')\n",
    "torch.save(tun4,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/normalize/tunning_value4.pt')\n",
    "torch.save(tun5,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/normalize/tunning_value5.pt')\n",
    "torch.save(tun6,'/scratch/bs4283/auditory_data/data_20sample/tunnning_value/new_tunning_value/normalize/tunning_value6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
